# 自然语言处理中的文本生成任务

自然语言处理(Natural language processing,NLP)是利用计算机技术对人类语言进行自动分析 和表征的方法及理论的总称. 自然语言处理研究 的目的是让计算机能够运行各种层次的自然语言相关任务，包括分词、词性标注、机器翻译、对话系统. 深度学习和自然语言处理发展到现在，已经能够部分解决一些相对复杂的文本生成任务，例如对话系统、机器翻译、图像描述和自动摘要等.

## 对话系统

对话系统通常也被叫作聊天机器人，或者基 于自然语言的人机交互

- 是面向特定任务的，目的是帮助用户完成特定的任务;任务导向的对话系统(Task-oriented spoken dialogue systems)可以完成类似预定酒店、提供餐厅信息和 获取公交时间表等任务. 这类系统通常依赖结构化的本体或者数据库，他们提供了系统交谈所需 要的领域知识;
- 开放领域的，以聊天交流为主要目的.开放领域对话不是以提供信息 为目的，一般是以与用户交流的情感体验为目标

## 机器翻译

机器翻译是计算机发展之初就企图解决的问题之一，目的是实现机器自动将一种语言转化为另一种语言.

- 早期方法是语言学家手动编写翻译规则实现机器翻译，但是人工设计规则的代价非常大，对语言学家的翻译功底要求非常高，并且规则很难覆盖所有的语言现象.
- 国际商业机器公司(IBM)在上世纪九十年代提出了统计机器翻译的方法，这种方法只需要人工设计基于词、短语和句子的各种特征，提供足够多的双语语料，就能相对快速地构建一套统计机器翻译系统 ( Statistical machine translation, SMT) ， 大大减少了翻译系统设计研发的难度，翻译性能也超越了基于规则的方法.于是机器翻译也从语言学家主导转向计算机科学家主导，在学术界和产业界中基于统计的方法也逐渐取代了基于规则的方法.
- 随着深度学习不断在图像和语音领域的各类任务中达到最先进水平，机器翻译的研究者也开始使用深度学习技术. 2014年谷歌的Sutskever等提 出 了序列到序列(Sequence to sequence, Seq2Seq)方法，同年，蒙特利尔大学的Cho等提出了类似的编码‒解码(Encoder-decoder)框架，之后几乎所有的神经机器翻译(Neural machine translation, NMT) 都是基于他们的模型进行改进实现的. 直到注意力机制的出现，才真正使得神经机器翻译在翻译质量上开始超越统计机器翻译，逐步统治机器翻译领域. 基于深度学习的神经机器翻译仅用不到三年时间，已经成为各类自然语言处理国际会 议中主要的机器翻译研究方法，同时也成为谷歌、 百度、微软等商用机器翻译系统的核心方法.
  
## 图像生成描述任务

图像生成描述任务是用一个或者多个句子描述图片内容，涉及机器学习、计算机视觉和自然语 言处理等领域，需要让模型能理解图片内容和图像的语义信息，并且能生成人类可读的正确描述. 此类任务也可以看作和上述机器翻译类似的过程，即翻译一张图片成为一段描述性文字. 所以可以借鉴机器翻译任务的很多方法和基础框架，通常也是采用编码‒解码器模型，编码器编码一张图片而解码器解码生成一段文字. 生成图像描述任务有很广泛的应用前景，例如基于文字的图像检索，为盲人用户提供帮助，人类与机器人交互等场景.

上述文本生成任务中存在大量难以建模表征的决策问题，而使用监督学习还不足以解决这样 复杂情景的决策任务. 于是具有强大表征和决策能力的深度强化学习可以很好应用于此类自然语言处理任务之中，近年来关于这方面的研究也涌现出很多优秀的方法和思想，下面首先介绍深度强化学习的分类和主要算法，然后结合文本生成任务，详细分析各种算法的创新点和优势，以及如何利用深度强化学习提高各类文本生成任务的效果

## 项目的思路

核心：文本生成+新闻的评论
好的立意：用于舆情方向的把控，新闻稿件或网络文字的预审核，起到风险的提前发现和控制
方案：文稿=》评论=》对评论进行舆情分析，粗细

技术：transformer XL, GAN, topic model, ASBA, 
